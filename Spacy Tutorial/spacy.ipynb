{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is one of the greatest films ever made. Brilliant acting by George C. Scott and Diane Riggs. This movie is both disturbing and extremely deep. Don't be fooled into believing this is just a comedy.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text=\"This is one of the greatest films ever made. Brilliant acting by George C. Scott and Diane Riggs. This movie is both disturbing and extremely deep. Don't be fooled into believing this is just a comedy.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "greatest\n",
      "films\n",
      "ever\n",
      "made\n",
      ".\n",
      "Brilliant\n",
      "acting\n",
      "by\n",
      "George\n",
      "C.\n",
      "Scott\n",
      "and\n",
      "Diane\n",
      "Riggs\n",
      ".\n",
      "This\n",
      "movie\n",
      "is\n",
      "both\n",
      "disturbing\n",
      "and\n",
      "extremely\n",
      "deep\n",
      ".\n",
      "Do\n",
      "n't\n",
      "be\n",
      "fooled\n",
      "into\n",
      "believing\n",
      "this\n",
      "is\n",
      "just\n",
      "a\n",
      "comedy\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Lemmatization example (Spacy lemmatization is superiar to nltk lemma)\n",
    "\n",
    "* Adjectives: happier, happiest → happy\n",
    "* Adverbs: worse, worst → badly\n",
    "* Nouns: dogs, children → dog, child\n",
    "* Verbs: writes, writing, wrote, written → write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organize        | organize        | AUX      | VB       | aux         | xxxx     |        1 |        0 | verb, base form |\n",
      "organizes       | organize        | VERB     | VBZ      | ROOT        | xxxx     |        1 |        0 | verb, 3rd person singular present |\n",
      "organizing      | organize        | VERB     | VBG      | xcomp       | xxxx     |        1 |        0 | verb, gerund or present participle |\n",
      "bad             | bad             | ADJ      | JJ       | dobj        | xxx      |        1 |        0 | adjective (English), other noun-modifier (Chinese) |\n",
      "badly           | badly           | ADV      | RB       | advmod      | xxxx     |        1 |        0 | adverb   |\n",
      "perhaps         | perhaps         | ADV      | RB       | advmod      | xxxx     |        1 |        1 | adverb   |\n"
     ]
    }
   ],
   "source": [
    "word_list=['organize', 'organizes', 'organizing','bad','badly','perhaps']\n",
    "for token in nlp(' '.join(word_list)):\n",
    "    print('{:15} | {:15} | {:8} | {:8} | {:11} | {:8} | {:8} | {:8} | {:8} |'.format(\n",
    "            token.text, token.lemma_, token.pos_, token.tag_, token.dep_\n",
    "            , token.shape_, token.is_alpha, token.is_stop, spacy.explain(token.tag_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organize organizes organizing bad badly perhaps'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_text = \"When I told John that I wanted to move to Alaska, he warned me that I'd have trouble finding a Starbucks there.\"\n",
    "ner_doc = nlp(ner_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John  :  PERSON  :  People, including fictional\n",
      "Alaska  :  GPE  :  Countries, cities, states\n",
      "Starbucks  :  ORG  :  Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in ner_doc.ents: #ents is entities\n",
    "    print(ent.text,' : ',ent.label_,' : ', spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When I told \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " that I wanted to move to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Alaska\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", he warned me that I'd have trouble finding a \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Starbucks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " there.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(ner_doc, style='ent')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Boundary Detection (SBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is a sentence', ' This is another sentence', \" let's go to N\", 'Y', '!']\n",
      "This is a sentence.\n",
      "This is another sentence.\n",
      "let's go to N.Y.!\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a sentence. This is another sentence. let's go to N.Y.!\"\n",
    "print(sentence.split('.'))\n",
    "\n",
    "doc = nlp(sentence)\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
